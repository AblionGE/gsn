\graphicspath{{chapters/ch-gsn/figures/}}

\chapter{GSN in Nutshell}%: Stream Processing Infrastructure for Large-scale Interconnected Streaming World

\section{Implementation}
\label{sec:implementation}

The GSN implementation consists of the GSN-CORE, implemented in Java, and the
platform-specific GSN-WRAPPERS, implemented in Java, C, and Ruby, depending on
the available toolkits for accessing specific types of sensors or sensor
networks. The implementation currently has approximately 80,000 lines of code
and is available from SourceForge (\url{http://gsn.sourceforge.net/}). GSN
is implemented to be highly modular in order to be deployable on various
hardware platforms from workstations to small programmable PDAs, i.e.,
depending on the specific platforms only a subset of modules may be used. GSN
also includes visualization systems for plotting data and visualizing the
network structure. In the following sections we are going to discuss some of
the key aspects of the GSN implementation

\subsection{Adding new sensor platforms}
\label{sec:adding-new-sensor}

For deploying a virtual sensor the user only has to specify an XML document as described in Section \ref{sec:virt-sens-spec}, if GSN already
includes software support for the concerned hardware/software. Adding a new
type of sensor or sensor network can be done by supplying the name of the wrapper (specified in \texttt{/conf/wrappers.properties})
conforming to the GSN API. At the moment GSN provides the following wrappers:

\begin{description}
\item[HTTP generic wrapper] is used to pull data from devices via HTTP GET
  or POST requests, for example, the AXIS206W wireless camera.

\item[TinyOS wrapper] enables interaction with TinyOS compatible
motes (version 1.x and 2.x). This wrapper uses the serial forwarder which is
the standard access tool for TinyOS provided in the TinyOS package.

\item[USB camera wrapper] is used for dealing with cameras connected via USB 
  to the local machine. As USB cameras are very cheap, they are quite
  popular as sensing devices. The wrapper supports cameras
  with OV518 and OV511 chips (see \url{http://alpha.dyndns.org/ov511/}).
  
\item[TI-RFID wrapper] enables access to Texas Instruments Series 6000 S6700
  multi-protocol RFID readers.

\item[Generic UDP wrapper] can be used for any device using the UDP protocol to
  send data.
  
\item[Generic serial wrapper] supports sensing devices which send data through
  the serial port.
\end{description}

Additionally, we provide template implementations for standard cases and
frequently used platforms. If wrapper implementations are shared publicly this
also facilitates building a reusable code base for virtually any sensor
platform. The effort to implement wrappers is quite low.

New wrappers can be added to GSN without having to rebuild or modify the GSN
server (plug-and-play). Upon startup GSN locates the wrapper mappings through reading
the \texttt{/conf/wrapper.properties} file and loads each wrapper whenever needed by the system.

%After that the wrappers for which virtual sensors
%have been initialized while unused wrappers do not consume
%resources.  Wrappers can also be parameterized, so that a virtual sensor can
%provide initialization parameters to the wrapper, e.g., the acceptable packet
%format for TinyOS.

\subsection{Dynamic resource management}
\label{sec:dynam-reso-manag}

The highly dynamic processing environment we target with GSN requires adaptive
dynamic resource management to allow the system to quickly react to changing
processing needs and environmental conditions. Dynamic resource management
accomplishes three main tasks:

\begin{description}
\item[Resource sharing:] As the user can modify/remove/add virtual sensors
  on-the-fly during runtime, the system needs to keep track of all resources
  used by the individual virtual sensors and enforce resource sharing among
  sensors (wrappers) where possible.
\item[Failure management:] If GSN detects a faulty virtual sensor or wrapper,
    e.g., by runtime exceptions, GSN undeploys it and releases the associated
    resources. 
  \item[Explicit resource control:] The user can specify explicit memory and
    processing requirements and restrictions. While restrictions are always
    enforced, requirements are handled depending of the globally available
    resources of the GSN instance. GSN tries to share the available resources
    in a fair way taking into account the explicitly specified resource
    requirements, if provided.
\end{description}

Dynamic resource management is performed at several levels in GSN as
shown in Figure~\ref{fig:resource-layers}. Separating the resource
sharing into several layers logically decouples the requirements and
allows us to achieve a higher level of reuse of resources. In the
following we will discuss the different levels.

\begin{figure}%[htb]
  \centering
  \includegraphics[width=0.5\columnwidth]{gsn-reuse}
  \caption{Hierarchical resource sharing in GSN}
  \label{fig:resource-layers}
\end{figure}

\textbf{Wrapper sharing.} Wrappers communicate directly with the sensors which
involves expensive I/O operations via a serial connection or wireless/wired
network communication. To minimize the costs incurred by these operations GSN
shares wrappers among virtual sensors accessing the same physical/virtual
sensors. To do so each GSN node maintains a repository of active wrappers. If a
new virtual sensor is deployed, the node first checks with the wrapper
repository whether an identical wrapper already exists, i.e., wrapper name and
initialization parameters (and their corresponding values) of the \verb|<wrapper>| element in the virtual sensor
definitions are identical. If a match is found, the new virtual sensor is
registered to the existing wrapper as a consumer. If not, a new wrapper
instance is created and registered with the wrapper repository. In the case of
remote sensor accesses this strategy is applied at both the sending and
receiving sides to maximize the sharing, i.e., multiple virtual sensors on one
GSN node share a wrapper for the same remote sensor and on the node hosting the
sensor the wrapper is shared among all nodes accessing it.

\textbf{Data sharing.} The raw input data produced by the wrappers is processed
and filtered by the source queries to generate the actual input data for the
input streams of a virtual sensor. For this purpose a source defines
what part of the raw input data is used by the associated source query
to produce the source's output data, i.e., by defining the available
storage, sampling rates, and window sizes a view on the raw data is defined on
which the source query is executed. In terms of the implementation each
wrapper is assigned a storage holding the raw data and source queries
are then defined as \emph{SQL views} on this data store.

This has a number of advantages: (1) It minimizes the storage consumption as
raw data is only stored once. Especially if the sensor data is large, e.g.,
image data, this is relevant. (2) If the sensor data comes from a
power-constrained or slow device, power is conserved and processing is sped up.
(3) Different processing strategies can be applied to the same data without
having to replicate it, for example, image enhancement algorithms and object
detection can use the same raw image data.

In the same way as a wrapper can be shared by multiple sources, a source
can also be shared among multiple streams at a higher level, and
streams in turn are shared by multiple virtual sensors. In essence each
of the layers in Figure~\ref{fig:resource-layers} can be viewed as a resource
pool where each of the individual resources in the pool can be shared among
multiple resources at the next higher level. Conversely, each higher level
resource can also use any number of lower level resources.

\subsection{Query planning and execution}
\label{sec:query-proc-optim}

In GSN each virtual sensor corresponds to a database table and each sensor
reading corresponds to a new tuple in the related table. As we use a standard
SQL database as our low-level query processing engine, the question is how to
represent the streaming logic in a form understandable for a standard database
engine (as already described, GSN separates the stream processing directives
from the query). We address this problem by using a query translator which gets
an SQL query and the stream processing directives as provided in the virtual
sensor definition as inputs and translates this into a query executable in a
standard database. The query translator relies on special support functions
which emulate stream-oriented constructs in a database. These support functions
are dependent on the database used and are provided by GSN (currently we
provide adapters for H2 and MySQL). Translated queries are cached for subsequent use.

Upon deployment of a virtual sensor $VS$, all queries $Q_i$ contained in its
specification are extracted. Each query $Q_i(VS_1,\dots,VS_n)$ accesses one or
more relations $VS_1,\dots,VS_n$ which correspond to virtual sensors. Then the
query translator translates each $Q_i(VS_1,\dots,VS_n)$ into an executable
query $Q^t_i(VS_1,\dots,VS_n)$ as described above and each
$Q^t_i(VS_1,\dots,VS_n)$ is declared as a view in the database with a unique
identifier $Id_i$. This means whenever a new tuple, i.e., sensor reading, is
added to the database, the concerned views will automatically be updated by the
database. Additionally, a tuple $(VS_j, Id_i, VS)$ for each $VS_j \in
{VS_1,\dots,VS_n}$ is added to a special view registration table. This
procedure is done once when a virtual sensor is deployed.

With this setup it is now simple to execute queries over the data streams
produced by virtual sensors: As soon a new sensor reading for a virtual sensor
$VS_d$ becomes available, it is entered into the appropriate database relation.
Then the database server queries the registration table using $VS_d$ as the key
and gets all identifiers $Id_r$ registered for new data of $VS_d$. Then simply
all views $V_r$ affected by the new data item can be retrieved using the $Id_r$
and all $V_r$ can be queried using a \texttt{SELECT * FROM} $\mathtt{V_r}$
statement and the resulting data can be returned to the virtual sensor
containing $V_r$ (third column in the registration table). Since views are
automatically updated by the database querying them is efficient. However, with
many registered views (thousands or more) scalability may suffer. Thus GSN does
not produce an individual query for each view but merges all queries into a
large select statement, and the result will then be joined with the view
registration table on the view identifier. Thus the result will hold tuples
that identify the virtual sensor to notify of the new data.  The reasons for
applying this strategy are that (1) database connections are expensive, (2)
with increasing number of clients and virtual sensor definitions, the
probability of overlaps in the result sets increases which automatically will
be exploited by the database's query processor, and (3) query execution in the
database is expensive, so one large query is much less costly than many
(possibly thousands) small ones.

Immediate notification of new sensor data is currently implemented in GSN and
is an eager strategy. As an alternative also a lazy strategy could be used
where the query execution would only take place when the GSN instance requests
it from the database, for example, periodically at regular intervals. In
practice the former can be implemented using views or triggers and the latter
can be implemented using inner selects or stored procedures.



\section{Evaluation \footnote{The evaluation results in this section correspond to GSN release 0.90}}
\label{sec:evaluation}

GSN aims at providing a zero-programming and efficient infrastructure for
large-scale interconnected sensor networks. To justify this claim we
experimentally evaluate the throughput of the local sensor data processing and
the performance and scalability of query processing as the key influencing
factors.  As virtual sensors are addressed explicitly and GSN nodes communicate
directly in a point-to-point (peer-to-peer) style, we can reasonably
extrapolate the experimental results presented in this section to larger
network sizes.  For our experiments, we used the setup shown in
Figure~\ref{fig:ExperimentalSetup}.

The GSN network consisted of 5 standard Dell desktop PCs with Pentium 4, 3.2GHz
Intel processors with 1MB cache, 1GB memory, 100Mbit Ethernet, running Debian
3.1 Linux with an unmodified kernel 2.4.27. For the storage layer use standard
MySQL 5.18.  The PCs were attached to the following sensor networks as shown in
Figure~\ref{fig:ExperimentalSetup}.

\begin{itemize}
  
\item A sensor network consisting of 10 Mica2 motes, each mote being equipped
  with light and temperature sensors. The packet size was configured to 15
  Bytes (data portion excluding the headers).
  
\item A sensor network consisting of 8 Mica2 motes, each equipped with light,
  temperature, acceleration, and sound sensors. The packet size was
  configured to 100 Bytes (data portion excluding the headers).  The maximum
  possible packet size for TinyOS 1.x packets of the current TinyOS
  implementation is 128 bytes (including headers).
  
\item A sensor network consisting of 4 Tiny-Nodes (TinyOS compatible motes
  produced by Shockfish, \url{http://www.shockfish.com/}), each equipped with a
  light and two temperature sensors with TinyOS standard packet size of 29
  Bytes.
  
\item 15 Wireless network cameras (AXIS 206W) which can capture 640x480 JPEG
  pictures with a rate of 30 frames per second. 5 cameras use the highest
  available compression (16kB average image size), 5 use medium compression
  (32kB average image size), and 5 use no compression (75kB average image
  size). The cameras are connected to a Linksys WRT54G wireless access point
  via 802.11b and the access point is connected via 100Mbit Ethernet to a GSN
  node.
  
\item A Texas Instruments Series 6000 S6700 multi-protocol RFID reader with
  three different kind of tags, which can keep up to 8KB of data.
  128 Bytes capacity.
  
\end{itemize}

The motes in each sensor network form a sensor network and routing among the
motes is done with the surge multi-hop ad-hoc routing algorithm provided by
TinyOS.

\begin{figure}%[htb]
  \centering
  \includegraphics[width=0.8\columnwidth]{setup}
  \caption{Experimental setup}
  \label{fig:ExperimentalSetup}
\end{figure}


\subsection{Internal processing time}
\label{sec:exepr-eval}

In the first experiment we wanted to determine the internal processing time a
GSN node requires for processing sensor readings, i.e., the time interval when
the wrapper gets the sensor data until the data can be provided to clients by
the associated virtual sensor. This delay depends on the size of the sensor
data and the rate at which the data is produced, but is independent of the
number of clients wanting to receive the sensor data. Thus it is a lower bound
and characterizes the efficiency of the implementation. 

We configured the 22 motes and 15 cameras to produce data every 10, 25, 50,
100, 250, 500, and 1000 milliseconds. As the cameras have a maximum rate of 30
frames/second, i.e., a frame every 33 milliseconds, we added a proxy between
the GSN node and the WRT54G access point which repeated the last available
frame in order to reach a frame interval of 10 milliseconds. All GSN instances
used the Sun Java Virtual Machine (1.5.0 update 6) with memory restricted to
64MB.

The experiment was conducted as follows: All motes and cameras were set to the
same rate and produced data for 8 hours and we measured the processing delay.
This was repeated 3 times for each rate and the measurements were averaged.
Figure~\ref{fig:TimeTriggeredLoad} shows the results of the experiment for the
different data sizes produced by the motes and the cameras.

\begin{figure}%[htb]
  \centering
  \includegraphics[width=0.8\columnwidth]{rates}
  \caption{GSN node under time-triggered load}
  \label{fig:TimeTriggeredLoad}
\end{figure}

High data rates put some stress on the system but the absolute delays are still
quite tolerable. The delays drop sharply if the interval is increased and then
converge to a nearly constant time at a rate of approximately 4 readings/second
or less. This result shows that GSN can tolerate high rates and incurs low
overhead for realistic rates as in practical sensor deployments lower rates are
more probable due to energy constraints of the sensor devices while still being
able to deal also with high rates.


\subsection{Scalability in the number of queries and clients}
\label{sec:scal-towards-numb}

In this experiment the goal was to measure GSN's scalability in the number of
clients and queries. To do so, we used two 1.8 GHz Centrino laptops with 1GB
memory as shown in Figure~\ref{fig:ExperimentalSetup} which each ran 250
lightweight GSN instances. The lightweight GSN instance only included those
components that we needed for the experiment. Each GSN-light instance used a
random query generator to generate queries with varying table names, varying
filtering condition complexity, and varying configuration parameters such as
history size, sampling rate, etc. For the experiments we configured the query
generator to produce random queries with 3 filtering predicates in the
\texttt{where} clause on average, using random history sizes from 1 second up
to 30 minutes and uniformly distributed random sampling rates (seconds) in the
interval $[0.01,1]$.

Then we configured the motes such that they produce a measurement each second
but would deliver it with a probability $P<1$, i.e., a reading would be dropped
with probability $1-P>0$.  Additionally, each mote could produce a burst of $R$
readings at the highest possible speed depending on the hardware with
probability $B>0$, where $R$ is a uniformly random integer from the interval
$[1,100]$. I.e., a burst would occur with a probability of $P * B$ and would
produce randomly 1 up to 100 data items.  In the experiments we used $P=0.85$
and $B=0.3$. On the desktops we used MySQL as the database with the recommended
configuration for large memory systems.
Figure~\ref{fig:QueryProcessingLatency} shows the results for a stream element
size (SES) of 30 Bytes. Using SES=32KB gives the same latencies. Due
to space limitations we do not include this figure.

\begin{figure}%[htb]
  \centering
  \includegraphics[width=0.8\columnwidth]{query-processing-time-30bytes}
%  \hspace{0.05\columnwidth}
%  \includegraphics[width=0.45\columnwidth]{query-processing-time-32KB}
  \caption{Query processing latencies in a node}
  \label{fig:QueryProcessingLatency}
\end{figure}

The spikes in the graphs are bursts as described above. Basically this
experiment measures the performance of the database server under various loads
which heavily depends on the used database. As expected the database server's
performance is directly related to the number of the clients as with the
increasing number of clients more queries are sent to the database and also the
cost of the query compiling increases. Nevertheless, the query processing time
is reasonably low as the graphs show that the average time to process a query
if 500 clients issue queries is less than 50ms, i.e., approximately 0.5ms per
client. If required, a cluster could be used to the improve query processing
times which is supported by most of the existing databases already.

In the next experiment shown in Figure~\ref{fig:ProcessingTimePerClient} we
look at the average processing time for a client excluding the query processing
part. In this experiment we used $P=0.85$, $B=0.05$, and $R$ is as above. 

We can make three interesting observations from
Figure~\ref{fig:ProcessingTimePerClient}:

\begin{enumerate}
\item  GSN only allocates resources for virtual sensors that are being
  used. The left side of the graph shows the situation when the first
  clients arrive and use virtual sensors. The system has to instantiate
  the virtual sensor and activates the necessary resources for query
  processing, notification, connection caching, etc. Thus for the
  first clients to arrive average processing times are a bit
  higher. CPU usage is around 34\% in this interval. After a short
  time (around 30 clients) the initialization phase is over and the
  average processing time decreases as the newly arriving clients can
  already use the services in place. CPU usage then drops to around
  12\%.
  
\item Again the spikes in the graph relate to bursts. Although the processing
  time increases considerably during the bursts, the system immediately
  restores its normal behavior with low processing times when the bursts are
  over, i.e., it is very responsive and quickly adopts to varying loads.

\item As the number of clients increases, the average processing time
  for each client decreases. This is due to the implemented data
  sharing functionalities. As the number of clients increases, also
  the probability of using common resources and data items grows.
\end{enumerate}

\begin{figure}%[htb]
  \centering
  \includegraphics[width=0.8\columnwidth]{processing-time-per-client}
  \caption{Processing time per client}
  \label{fig:ProcessingTimePerClient}
\end{figure}

\section{Related work}
\label{sec:relatedwork}

So far only few architectures to support interconnected sensor networks exist.
Sgroi et al.~\cite{Sgroi05} suggest basic abstractions, a standard set of
services, and an API to free application developers from the details of the
underlying sensor networks.  However, the focus is on systematic definition and
classification of abstractions and services, while GSN takes a more general
view and provides not only APIs but a complete query processing and management
infrastructure with a declarative language interface.

Hourglass~\cite{Shneidman04} provides an Internet-based infrastructure for
connecting sensor networks to applications and offers topic-based discovery and
data-processing services. Similar to GSN it tries to hide internals of sensors
from the user but focuses on maintaining quality of service of data streams in
the presence of disconnections while GSN is more targeted at flexible
configurations, general abstractions, and distributed query support.

HiFi~\cite{Franklin05} provides efficient, hierarchical data stream query
processing to acquire, filter, and aggregate data from multiple devices in a
static environment while GSN takes a peer-to-peer perspective assuming a
dynamic environment and allowing any node to be a data source, data sink, or
data aggregator.

IrisNet~\cite{Gibbons03} proposes a two-tier architecture consisting of sensing
agents (SA) which collect and pre-process sensor data and organizing agents
(OA) which store sensor data in a hierarchical, distributed XML database. This
database is modeled after the design of the Internet DNS and supports XPath
queries. In contrast to that, GSN follows a symmetric peer-to-peer approach as
already mentioned and supports relational queries using SQL.

Rooney et al.~\cite{Rooney06} propose so-called EdgeServers to integrate sensor
networks into enterprise networks. EdgeServers filter and aggregate raw sensor
data (using application specific code) to reduce the amount of data forwarded
to application servers. The system uses publish/subscribe style communication
and also includes specialized protocols for the integration of sensor
networks. While GSN provides a general-purpose infrastructure for sensor
network deployment and distributed query processing, the EdgeServer system
targets enterprise networks with application-based customization to reduce
sensor data traffic in closed environments.

Besides these architectures, a large number of systems for query processing in
sensor networks exist. Aurora~\cite{Cherniack03} (Brandeis University, Braun
University, MIT), STREAM~\cite{Arasu06} (Stanford),
TelegraphCQ~\cite{Chandrasekaran03} (UC Berkeley), and Cougar~\cite{Yao03}
(Cornell) have already been discussed and related to GSN in
Section~\ref{sec:data-stre-proc}.

%The Aurora project~\cite{Cherniack03} is a general-purpose centralized stream
%processing engine. Streams are modeled as sequences of time-stamped tuples, and
%users can compose stream relationships and construct queries in a graphical
%representation which is then used as input for the query planner.

In the Medusa distributed stream-processing system~\cite{Zdonik03}, Aurora is
being used as the processing engine on each of the participating nodes. Medusa
takes Aurora queries and distributes them across multiple nodes and
particularly focuses on load management using economic principles and high
availability issues. The Borealis stream processing engine~\cite{Abadi05} is
based on the work in Medusa and Aurora and supports dynamic query modification,
dynamic revision of query results, and flexible optimization. These systems
focus on (distributed) query processing only, which is only one specific
component of GSN, and focus on sensor heavy and server heavy application
domains.

Additionally, several systems providing publish/subscribe-style query
processing comparable to GSN exist, for example, \cite{Gray05}.

\section{Conclusions}
\label{sec:conclusions}

The full potential of sensor technology will be unleashed through large-scale
(up to global scale) data-oriented integration of sensor networks. To realize
this vision of a ``Sensor Internet'' we suggest our Global Sensor Networks
(GSN) middleware which enables fast and flexible deployment and interconnection
of sensor networks. Through its virtual sensor abstraction which can abstract
from arbitrary stream data sources and its powerful declarative specification
and query tools, GSN provides simple and uniform access to the host of
heterogeneous technologies. GSN offers zero-programming deployment and
data-oriented integration of sensor networks and supports dynamic configuration
and adaptation at runtime. Zero-programming deployment in conjunction with
GSN's plug-and-play detection and deployment feature provides a basic
functionality to enable sensor mobility. GSN is implemented in Java and C/C++
and is available from SourceForge at \url{http://gsn.sourcefourge.net/}.
The experimental evaluation of GSN demonstrates that the implementation is
highly efficient, offers very good performance and throughput even under high
loads and scales gracefully in the number of nodes, queries, and query
complexity.




